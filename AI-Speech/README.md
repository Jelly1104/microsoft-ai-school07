# AI 음성 챗봇 서비스 개발 프로젝트

## 1. 학습 목표

- **API 활용 능력:** Microsoft Azure Cognitive Services (STT, TTS) 및 OpenAI (GPT)의 REST API를 호출하고, 응답을 처리하는 방법을 학습합니다.
- **외부 라이브러리 연동:** `requests` 라이브러리를 사용하여 외부 API와 통신하고, `gradio` 라이브러리를 활용하여 웹 기반의 대화형 인터페이스를 구축하는 기술을 익힙니다.
- **음성 데이터 처리:** 오디오 파일을 API 요청의 일부로 전송하고, API로부터 받은 음성 데이터를 파일로 저장 및 재생하는 과정을 이해합니다.
- **서비스 통합 설계:** STT(음성-텍스트 변환), GPT(자연어 처리 및 생성), TTS(텍스트-음성 변환) 세 가지 핵심 AI 기능을 하나의 서비스로 통합하여 완전한 음성 챗봇 파이프라인을 구축하는 능력을 기릅니다.
- **대화형 애플리케이션 개발:** 사용자의 음성 입력을 받아 텍스트로 변환하고, AI가 생성한 답변을 다시 음성으로 출력하는 전체적인 대화형 애플리케이션의 구조를 설계하고 구현하는 경험을 합니다.

## 2. 프로젝트 개요

이 프로젝트는 Microsoft Azure의 STT(Speech-to-Text), TTS(Text-to-Speech) 서비스와 OpenAI의 GPT 모델을 결합하여, 사용자와 음성으로 대화할 수 있는 AI 챗봇을 개발하는 것을 목표로 합니다. 사용자가 마이크를 통해 질문을 하면, STT가 이를 텍스트로 변환합니다. 변환된 텍스트는 GPT 모델로 전송되어 적절한 답변을 생성하고, 마지막으로 TTS가 이 답변을 자연스러운 음성으로 변환하여 사용자에게 들려줍니다. 이 모든 과정을 `gradio`를 활용한 웹 UI에 통합하여 사용자가 쉽게 상호작용할 수 있는 음성 챗봇 서비스를 완성합니다.

## 3. 파일 구성 및 설명

- **`0630+1+speech+STT+TTS+OpenAI_강사님.ipynb`**: 프로젝트 1일차 파일입니다. STT, TTS, GPT 각각의 API를 호출하는 기본 함수를 구현하고, `gradio`를 사용하여 각 기능을 개별적으로 테스트하는 UI를 구성합니다.
- **`0701+1+speech+STT+TTS+OpenAI_강사님.ipynb`**: 프로젝트 2일차 파일입니다. 1일차에 구현된 개별 기능들을 통합하여, STT -> GPT -> TTS로 이어지는 완전한 음성 챗봇 파이프라인을 구축하고, 대화 기록을 관리하는 챗봇 인터페이스를 완성합니다.

## 4. 서비스 설계

이 프로젝트는 세 가지 핵심 AI 모듈을 순차적으로 연결하는 파이프라인 형태로 설계되었습니다.

1.  **음성 입력 및 STT (Speech-to-Text):**
    - `gradio`의 `Audio` 컴포넌트를 사용하여 사용자의 마이크 입력을 받습니다.
    - 녹음된 오디오 파일은 Azure STT API로 전송됩니다.
    - API는 음성을 텍스트로 변환하여 반환하고, 이 결과는 UI에 표시됩니다.
2.  **텍스트 처리 및 GPT (Generative Pre-trained Transformer):**
    - STT를 통해 변환된 텍스트 또는 사용자가 직접 입력한 텍스트를 OpenAI GPT API로 전송합니다.
    - GPT 모델은 입력된 텍스트(질문)의 맥락을 이해하고 자연스러운 언어로 답변을 생성합니다.
    - 대화의 연속성을 위해 이전 대화 기록을 함께 관리합니다.
3.  **음성 출력 및 TTS (Text-to-Speech):**
    - GPT가 생성한 텍스트 답변을 Azure TTS API로 전송합니다.
    - TTS API는 SSML(Speech Synthesis Markup Language) 형식을 사용하여 특정 목소리(예: `ko-KR-SunHiNeural`)로 텍스트를 음성으로 변환합니다.
    - 변환된 음성 데이터는 `.wav` 파일로 저장되고, `gradio`의 `Audio` 컴포넌트를 통해 자동으로 재생됩니다.
4.  **사용자 인터페이스 (UI):**
    - `gradio` 라이브러리를 사용하여 전체 서비스를 웹 UI로 통합합니다.
    - 챗봇, 텍���트 입력창, 오디오 입/출력 컴포넌트를 배치하여 사용자가 직관적으로 서비스를 이용할 수 있도록 설계합니다.

## 5. 주요 실행 과정 및 결과

- **(1일차) 개별 기능 구현:**
    - `requests.post`를 사용하여 Azure STT, TTS 및 OpenAI GPT API를 호출하는 각각의 함수(`request_stt`, `request_tts`, `request_gpt`)를 성공적으로 구현했습니다.
    - `gradio`를 사용하여 각 기능을 독립적으로 테스트할 수 있는 간단한 UI를 구축하여 API 연동을 확인했습니다.
- **(2일차) 서비스 통합 및 완성:**
    - 1일차에 만든 함수들을 유기적으로 연결하여, 사용자의 음성 입력이 STT, GPT, TTS를 순차적으로 거쳐 음성 답변으로 돌아오는 완전한 파이프라인을 구축했습니다.
    - `gradio`의 `Chatbot` 컴포넌트를 활용하여 사용자와 AI 간의 대화 기록을 시각적으로 보여주고, 이를 통해 맥락을 유지하는 대화형 인터페이스를 완성했습니다.
    - 최종적으로 사용자가 "오늘 날씨 어때?"라고 음성으로 물으면, AI가 "오늘 서울의 날씨는 맑고 기온은 25도입니다."라고 텍스트와 음성으로 동시에 답변하는 통합 음성 챗봇 애플리케이션을 성공적으로 시연했습니다.

## 6. 학습 정리

- **API 기반 서비스 구축:** 여러 상용 AI API를 조합하여 새로운 가치를 창출하는 서비스 개발 방법을 실습을 통해 체득했습니다. 각기 다른 API의 요청/응답 형식을 이해하고 데이터를 적절히 가공하는 능력을 길렀습니다.
- **빠른 프로토타이핑:** `gradio`와 같은 도구를 활용하면 복잡한 웹 개발 과정 없이도 AI 모델 및 서비스를 위한 직관적인 UI를 신속하게 구축하고 테스트할 수 있음을 경험했습니다.
- **시스템 통합의 이해:** 단일 기능이 아닌 여러 시스템(STT, LLM, TTS)을 논리적 흐름에 따라 연결하고 데이터 파이프라인을 설계하는 시스템 통합 역량을 향상시켰습니다.
- **AI 서비스의 실제:** 텍스트 기반의 챗봇을 넘어, 음성이라는 매체를 통해 사용자와 상호작용하는 AI 서비스를 직접 구현해보며, AI 기술이 실생활에 어떻게 적용될 수 있는지 구체적으로 이해하게 되었습니다.
